{
  "best_metric": 0.20242996513843536,
  "best_model_checkpoint": "./outputs/lora-out-h100/checkpoint-250",
  "epoch": 0.748013090229079,
  "eval_steps": 50,
  "global_step": 400,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0018700327255726976,
      "eval_loss": 1.5435271263122559,
      "eval_runtime": 176.4754,
      "eval_samples_per_second": 5.57,
      "eval_steps_per_second": 1.394,
      "step": 1
    },
    {
      "epoch": 0.0037400654511453952,
      "grad_norm": 0.6503702998161316,
      "learning_rate": 2.6666666666666667e-05,
      "loss": 1.6705,
      "step": 2
    },
    {
      "epoch": 0.0074801309022907905,
      "grad_norm": 0.5219315886497498,
      "learning_rate": 5.333333333333333e-05,
      "loss": 1.6149,
      "step": 4
    },
    {
      "epoch": 0.011220196353436185,
      "grad_norm": 0.6990357041358948,
      "learning_rate": 8e-05,
      "loss": 1.3968,
      "step": 6
    },
    {
      "epoch": 0.014960261804581581,
      "grad_norm": 0.7029207348823547,
      "learning_rate": 0.00010666666666666667,
      "loss": 1.2783,
      "step": 8
    },
    {
      "epoch": 0.018700327255726974,
      "grad_norm": 0.9301720857620239,
      "learning_rate": 0.00013333333333333334,
      "loss": 1.1699,
      "step": 10
    },
    {
      "epoch": 0.02244039270687237,
      "grad_norm": 0.7891894578933716,
      "learning_rate": 0.00016,
      "loss": 1.1765,
      "step": 12
    },
    {
      "epoch": 0.026180458158017766,
      "grad_norm": 0.6247246861457825,
      "learning_rate": 0.0001866666666666667,
      "loss": 1.0596,
      "step": 14
    },
    {
      "epoch": 0.029920523609163162,
      "grad_norm": 0.7438219785690308,
      "learning_rate": 0.00019999816796524643,
      "loss": 1.0043,
      "step": 16
    },
    {
      "epoch": 0.033660589060308554,
      "grad_norm": 0.49335554242134094,
      "learning_rate": 0.00019998351208997734,
      "loss": 1.0127,
      "step": 18
    },
    {
      "epoch": 0.03740065451145395,
      "grad_norm": 0.6649758815765381,
      "learning_rate": 0.00019995420248742534,
      "loss": 0.8813,
      "step": 20
    },
    {
      "epoch": 0.04114071996259935,
      "grad_norm": 0.5979806184768677,
      "learning_rate": 0.0001999102434532479,
      "loss": 0.9048,
      "step": 22
    },
    {
      "epoch": 0.04488078541374474,
      "grad_norm": 0.7310483455657959,
      "learning_rate": 0.00019985164143014432,
      "loss": 0.7555,
      "step": 24
    },
    {
      "epoch": 0.04862085086489014,
      "grad_norm": 0.6332868933677673,
      "learning_rate": 0.00019977840500691132,
      "loss": 0.9573,
      "step": 26
    },
    {
      "epoch": 0.05236091631603553,
      "grad_norm": 0.5072218775749207,
      "learning_rate": 0.00019969054491718435,
      "loss": 0.773,
      "step": 28
    },
    {
      "epoch": 0.056100981767180924,
      "grad_norm": 0.5775941014289856,
      "learning_rate": 0.00019958807403786452,
      "loss": 0.6524,
      "step": 30
    },
    {
      "epoch": 0.059841047218326324,
      "grad_norm": 0.9692696928977966,
      "learning_rate": 0.00019947100738723126,
      "loss": 0.6993,
      "step": 32
    },
    {
      "epoch": 0.06358111266947171,
      "grad_norm": 0.4888778030872345,
      "learning_rate": 0.00019933936212274115,
      "loss": 0.6815,
      "step": 34
    },
    {
      "epoch": 0.06732117812061711,
      "grad_norm": 0.5659366846084595,
      "learning_rate": 0.00019919315753851342,
      "loss": 0.6531,
      "step": 36
    },
    {
      "epoch": 0.07106124357176251,
      "grad_norm": 0.6130831241607666,
      "learning_rate": 0.0001990324150625022,
      "loss": 0.5921,
      "step": 38
    },
    {
      "epoch": 0.0748013090229079,
      "grad_norm": 0.6782793998718262,
      "learning_rate": 0.00019885715825335582,
      "loss": 0.6185,
      "step": 40
    },
    {
      "epoch": 0.0785413744740533,
      "grad_norm": 1.0387279987335205,
      "learning_rate": 0.00019866741279696423,
      "loss": 0.6269,
      "step": 42
    },
    {
      "epoch": 0.0822814399251987,
      "grad_norm": 0.6817920207977295,
      "learning_rate": 0.0001984632065026943,
      "loss": 0.4641,
      "step": 44
    },
    {
      "epoch": 0.08602150537634409,
      "grad_norm": 0.6851357817649841,
      "learning_rate": 0.00019824456929931416,
      "loss": 0.5308,
      "step": 46
    },
    {
      "epoch": 0.08976157082748948,
      "grad_norm": 0.5051515102386475,
      "learning_rate": 0.0001980115332306067,
      "loss": 0.3879,
      "step": 48
    },
    {
      "epoch": 0.09350163627863488,
      "grad_norm": 0.6575045585632324,
      "learning_rate": 0.00019776413245067305,
      "loss": 0.3747,
      "step": 50
    },
    {
      "epoch": 0.09350163627863488,
      "eval_loss": 0.6354507803916931,
      "eval_runtime": 177.2843,
      "eval_samples_per_second": 5.545,
      "eval_steps_per_second": 1.388,
      "step": 50
    },
    {
      "epoch": 0.09724170172978028,
      "grad_norm": 0.8186578154563904,
      "learning_rate": 0.00019750240321892744,
      "loss": 0.3515,
      "step": 52
    },
    {
      "epoch": 0.10098176718092566,
      "grad_norm": 0.42811980843544006,
      "learning_rate": 0.00019722638389478217,
      "loss": 0.3333,
      "step": 54
    },
    {
      "epoch": 0.10472183263207106,
      "grad_norm": 0.25359097123146057,
      "learning_rate": 0.00019693611493202637,
      "loss": 0.2626,
      "step": 56
    },
    {
      "epoch": 0.10846189808321646,
      "grad_norm": 0.506172239780426,
      "learning_rate": 0.0001966316388728965,
      "loss": 0.3025,
      "step": 58
    },
    {
      "epoch": 0.11220196353436185,
      "grad_norm": 0.3147100508213043,
      "learning_rate": 0.00019631300034184153,
      "loss": 0.2624,
      "step": 60
    },
    {
      "epoch": 0.11594202898550725,
      "grad_norm": 0.5480403304100037,
      "learning_rate": 0.00019598024603898273,
      "loss": 0.3231,
      "step": 62
    },
    {
      "epoch": 0.11968209443665265,
      "grad_norm": 0.40910762548446655,
      "learning_rate": 0.00019563342473326913,
      "loss": 0.2751,
      "step": 64
    },
    {
      "epoch": 0.12342215988779803,
      "grad_norm": 0.6119568943977356,
      "learning_rate": 0.00019527258725532992,
      "loss": 0.2508,
      "step": 66
    },
    {
      "epoch": 0.12716222533894342,
      "grad_norm": 0.3329598605632782,
      "learning_rate": 0.0001948977864900247,
      "loss": 0.2181,
      "step": 68
    },
    {
      "epoch": 0.13090229079008883,
      "grad_norm": 0.4511134624481201,
      "learning_rate": 0.00019450907736869244,
      "loss": 0.2134,
      "step": 70
    },
    {
      "epoch": 0.13464235624123422,
      "grad_norm": 0.4111522138118744,
      "learning_rate": 0.0001941065168611009,
      "loss": 0.2232,
      "step": 72
    },
    {
      "epoch": 0.1383824216923796,
      "grad_norm": 0.3527434170246124,
      "learning_rate": 0.00019369016396709681,
      "loss": 0.1845,
      "step": 74
    },
    {
      "epoch": 0.14212248714352502,
      "grad_norm": 0.3895878195762634,
      "learning_rate": 0.0001932600797079589,
      "loss": 0.2025,
      "step": 76
    },
    {
      "epoch": 0.1458625525946704,
      "grad_norm": 0.5028605461120605,
      "learning_rate": 0.0001928163271174546,
      "loss": 0.2007,
      "step": 78
    },
    {
      "epoch": 0.1496026180458158,
      "grad_norm": 0.3090476393699646,
      "learning_rate": 0.00019235897123260154,
      "loss": 0.191,
      "step": 80
    },
    {
      "epoch": 0.1533426834969612,
      "grad_norm": 0.4368210732936859,
      "learning_rate": 0.0001918880790841358,
      "loss": 0.1704,
      "step": 82
    },
    {
      "epoch": 0.1570827489481066,
      "grad_norm": 0.48101893067359924,
      "learning_rate": 0.00019140371968668767,
      "loss": 0.1605,
      "step": 84
    },
    {
      "epoch": 0.16082281439925197,
      "grad_norm": 0.3782925307750702,
      "learning_rate": 0.0001909059640286668,
      "loss": 0.1327,
      "step": 86
    },
    {
      "epoch": 0.1645628798503974,
      "grad_norm": 0.31012409925460815,
      "learning_rate": 0.00019039488506185807,
      "loss": 0.1485,
      "step": 88
    },
    {
      "epoch": 0.16830294530154277,
      "grad_norm": 0.45268514752388,
      "learning_rate": 0.00018987055769072972,
      "loss": 0.1197,
      "step": 90
    },
    {
      "epoch": 0.17204301075268819,
      "grad_norm": 0.3502069115638733,
      "learning_rate": 0.00018933305876145506,
      "loss": 0.1382,
      "step": 92
    },
    {
      "epoch": 0.17578307620383357,
      "grad_norm": 0.41033825278282166,
      "learning_rate": 0.00018878246705064994,
      "loss": 0.0963,
      "step": 94
    },
    {
      "epoch": 0.17952314165497896,
      "grad_norm": 0.39400020241737366,
      "learning_rate": 0.00018821886325382718,
      "loss": 0.1597,
      "step": 96
    },
    {
      "epoch": 0.18326320710612437,
      "grad_norm": 0.4502503275871277,
      "learning_rate": 0.0001876423299735695,
      "loss": 0.1186,
      "step": 98
    },
    {
      "epoch": 0.18700327255726976,
      "grad_norm": 0.3973938524723053,
      "learning_rate": 0.00018705295170742337,
      "loss": 0.1048,
      "step": 100
    },
    {
      "epoch": 0.18700327255726976,
      "eval_loss": 0.3937242031097412,
      "eval_runtime": 177.2063,
      "eval_samples_per_second": 5.547,
      "eval_steps_per_second": 1.388,
      "step": 100
    },
    {
      "epoch": 0.19074333800841514,
      "grad_norm": 0.5498871803283691,
      "learning_rate": 0.00018645081483551488,
      "loss": 0.0889,
      "step": 102
    },
    {
      "epoch": 0.19448340345956056,
      "grad_norm": 0.582143247127533,
      "learning_rate": 0.00018583600760788967,
      "loss": 0.1307,
      "step": 104
    },
    {
      "epoch": 0.19822346891070594,
      "grad_norm": 0.35605186223983765,
      "learning_rate": 0.00018520862013157897,
      "loss": 0.0896,
      "step": 106
    },
    {
      "epoch": 0.20196353436185133,
      "grad_norm": 0.5464434027671814,
      "learning_rate": 0.00018456874435739335,
      "loss": 0.0977,
      "step": 108
    },
    {
      "epoch": 0.20570359981299674,
      "grad_norm": 0.4275071322917938,
      "learning_rate": 0.0001839164740664462,
      "loss": 0.116,
      "step": 110
    },
    {
      "epoch": 0.20944366526414213,
      "grad_norm": 0.37077584862709045,
      "learning_rate": 0.00018325190485640923,
      "loss": 0.0748,
      "step": 112
    },
    {
      "epoch": 0.2131837307152875,
      "grad_norm": 0.3929278254508972,
      "learning_rate": 0.0001825751341275013,
      "loss": 0.0811,
      "step": 114
    },
    {
      "epoch": 0.21692379616643293,
      "grad_norm": 0.38775065541267395,
      "learning_rate": 0.00018188626106821346,
      "loss": 0.0709,
      "step": 116
    },
    {
      "epoch": 0.2206638616175783,
      "grad_norm": 0.2784149944782257,
      "learning_rate": 0.00018118538664077175,
      "loss": 0.0501,
      "step": 118
    },
    {
      "epoch": 0.2244039270687237,
      "grad_norm": 0.3090181350708008,
      "learning_rate": 0.0001804726135663399,
      "loss": 0.0659,
      "step": 120
    },
    {
      "epoch": 0.2281439925198691,
      "grad_norm": 0.35693684220314026,
      "learning_rate": 0.00017974804630996446,
      "loss": 0.0485,
      "step": 122
    },
    {
      "epoch": 0.2318840579710145,
      "grad_norm": 0.3530677258968353,
      "learning_rate": 0.00017901179106526434,
      "loss": 0.0513,
      "step": 124
    },
    {
      "epoch": 0.23562412342215988,
      "grad_norm": 0.2542024552822113,
      "learning_rate": 0.00017826395573886672,
      "loss": 0.033,
      "step": 126
    },
    {
      "epoch": 0.2393641888733053,
      "grad_norm": 0.34422215819358826,
      "learning_rate": 0.00017750464993459222,
      "loss": 0.0492,
      "step": 128
    },
    {
      "epoch": 0.24310425432445068,
      "grad_norm": 0.3226054608821869,
      "learning_rate": 0.00017673398493739118,
      "loss": 0.0463,
      "step": 130
    },
    {
      "epoch": 0.24684431977559607,
      "grad_norm": 0.2534450888633728,
      "learning_rate": 0.0001759520736970337,
      "loss": 0.0329,
      "step": 132
    },
    {
      "epoch": 0.2505843852267415,
      "grad_norm": 0.21307817101478577,
      "learning_rate": 0.00017515903081155525,
      "loss": 0.0348,
      "step": 134
    },
    {
      "epoch": 0.25432445067788684,
      "grad_norm": 0.3125240206718445,
      "learning_rate": 0.0001743549725104614,
      "loss": 0.0325,
      "step": 136
    },
    {
      "epoch": 0.25806451612903225,
      "grad_norm": 0.23600710928440094,
      "learning_rate": 0.00017354001663769276,
      "loss": 0.0326,
      "step": 138
    },
    {
      "epoch": 0.26180458158017766,
      "grad_norm": 0.21760956943035126,
      "learning_rate": 0.00017271428263435375,
      "loss": 0.0303,
      "step": 140
    },
    {
      "epoch": 0.265544647031323,
      "grad_norm": 0.18662850558757782,
      "learning_rate": 0.0001718778915212071,
      "loss": 0.0231,
      "step": 142
    },
    {
      "epoch": 0.26928471248246844,
      "grad_norm": 0.21640299260616302,
      "learning_rate": 0.00017103096588093686,
      "loss": 0.0219,
      "step": 144
    },
    {
      "epoch": 0.27302477793361385,
      "grad_norm": 0.22124114632606506,
      "learning_rate": 0.00017017362984018256,
      "loss": 0.0249,
      "step": 146
    },
    {
      "epoch": 0.2767648433847592,
      "grad_norm": 0.19796518981456757,
      "learning_rate": 0.0001693060090513469,
      "loss": 0.0215,
      "step": 148
    },
    {
      "epoch": 0.2805049088359046,
      "grad_norm": 0.2564674913883209,
      "learning_rate": 0.00016842823067418018,
      "loss": 0.0222,
      "step": 150
    },
    {
      "epoch": 0.2805049088359046,
      "eval_loss": 0.28924715518951416,
      "eval_runtime": 176.7257,
      "eval_samples_per_second": 5.562,
      "eval_steps_per_second": 1.392,
      "step": 150
    },
    {
      "epoch": 0.28424497428705003,
      "grad_norm": 0.2143743932247162,
      "learning_rate": 0.00016754042335714333,
      "loss": 0.0206,
      "step": 152
    },
    {
      "epoch": 0.2879850397381954,
      "grad_norm": 0.255275160074234,
      "learning_rate": 0.00016664271721855323,
      "loss": 0.026,
      "step": 154
    },
    {
      "epoch": 0.2917251051893408,
      "grad_norm": 0.17022746801376343,
      "learning_rate": 0.0001657352438275122,
      "loss": 0.0223,
      "step": 156
    },
    {
      "epoch": 0.2954651706404862,
      "grad_norm": 0.12600071728229523,
      "learning_rate": 0.00016481813618462513,
      "loss": 0.0161,
      "step": 158
    },
    {
      "epoch": 0.2992052360916316,
      "grad_norm": 0.21264557540416718,
      "learning_rate": 0.00016389152870250676,
      "loss": 0.0171,
      "step": 160
    },
    {
      "epoch": 0.302945301542777,
      "grad_norm": 0.20176614820957184,
      "learning_rate": 0.00016295555718608191,
      "loss": 0.0172,
      "step": 162
    },
    {
      "epoch": 0.3066853669939224,
      "grad_norm": 0.23660603165626526,
      "learning_rate": 0.00016201035881268166,
      "loss": 0.0258,
      "step": 164
    },
    {
      "epoch": 0.31042543244506776,
      "grad_norm": 0.14347364008426666,
      "learning_rate": 0.0001610560721119386,
      "loss": 0.0149,
      "step": 166
    },
    {
      "epoch": 0.3141654978962132,
      "grad_norm": 0.14880968630313873,
      "learning_rate": 0.00016009283694548362,
      "loss": 0.0154,
      "step": 168
    },
    {
      "epoch": 0.3179055633473586,
      "grad_norm": 0.11015896499156952,
      "learning_rate": 0.00015912079448644764,
      "loss": 0.0146,
      "step": 170
    },
    {
      "epoch": 0.32164562879850395,
      "grad_norm": 0.11111230403184891,
      "learning_rate": 0.00015814008719877096,
      "loss": 0.0152,
      "step": 172
    },
    {
      "epoch": 0.32538569424964936,
      "grad_norm": 0.2017301619052887,
      "learning_rate": 0.00015715085881632366,
      "loss": 0.0192,
      "step": 174
    },
    {
      "epoch": 0.3291257597007948,
      "grad_norm": 0.14336369931697845,
      "learning_rate": 0.00015615325432183976,
      "loss": 0.0142,
      "step": 176
    },
    {
      "epoch": 0.33286582515194013,
      "grad_norm": 0.12018828094005585,
      "learning_rate": 0.00015514741992566825,
      "loss": 0.0129,
      "step": 178
    },
    {
      "epoch": 0.33660589060308554,
      "grad_norm": 0.11564037203788757,
      "learning_rate": 0.0001541335030443444,
      "loss": 0.0126,
      "step": 180
    },
    {
      "epoch": 0.34034595605423096,
      "grad_norm": 0.13328978419303894,
      "learning_rate": 0.00015311165227898407,
      "loss": 0.013,
      "step": 182
    },
    {
      "epoch": 0.34408602150537637,
      "grad_norm": 0.10271718353033066,
      "learning_rate": 0.0001520820173935046,
      "loss": 0.0121,
      "step": 184
    },
    {
      "epoch": 0.34782608695652173,
      "grad_norm": 0.10288719087839127,
      "learning_rate": 0.00015104474929267521,
      "loss": 0.0115,
      "step": 186
    },
    {
      "epoch": 0.35156615240766714,
      "grad_norm": 0.0894852802157402,
      "learning_rate": 0.00015000000000000001,
      "loss": 0.0096,
      "step": 188
    },
    {
      "epoch": 0.35530621785881256,
      "grad_norm": 0.09247481822967529,
      "learning_rate": 0.00014894792263543745,
      "loss": 0.0129,
      "step": 190
    },
    {
      "epoch": 0.3590462833099579,
      "grad_norm": 0.13511881232261658,
      "learning_rate": 0.0001478886713929587,
      "loss": 0.0136,
      "step": 192
    },
    {
      "epoch": 0.3627863487611033,
      "grad_norm": 0.10956237465143204,
      "learning_rate": 0.0001468224015179488,
      "loss": 0.0096,
      "step": 194
    },
    {
      "epoch": 0.36652641421224874,
      "grad_norm": 0.12880392372608185,
      "learning_rate": 0.00014574926928445365,
      "loss": 0.0105,
      "step": 196
    },
    {
      "epoch": 0.3702664796633941,
      "grad_norm": 0.0910966694355011,
      "learning_rate": 0.0001446694319722763,
      "loss": 0.0096,
      "step": 198
    },
    {
      "epoch": 0.3740065451145395,
      "grad_norm": 0.09817689657211304,
      "learning_rate": 0.00014358304784392568,
      "loss": 0.0088,
      "step": 200
    },
    {
      "epoch": 0.3740065451145395,
      "eval_loss": 0.20542225241661072,
      "eval_runtime": 176.7259,
      "eval_samples_per_second": 5.562,
      "eval_steps_per_second": 1.392,
      "step": 200
    },
    {
      "epoch": 0.3777466105656849,
      "grad_norm": 0.10808330774307251,
      "learning_rate": 0.00014249027612142173,
      "loss": 0.0107,
      "step": 202
    },
    {
      "epoch": 0.3814866760168303,
      "grad_norm": 0.10701403021812439,
      "learning_rate": 0.00014139127696295912,
      "loss": 0.0115,
      "step": 204
    },
    {
      "epoch": 0.3852267414679757,
      "grad_norm": 0.09398741275072098,
      "learning_rate": 0.00014028621143943464,
      "loss": 0.0087,
      "step": 206
    },
    {
      "epoch": 0.3889668069191211,
      "grad_norm": 0.09532537311315536,
      "learning_rate": 0.00013917524151084017,
      "loss": 0.0086,
      "step": 208
    },
    {
      "epoch": 0.39270687237026647,
      "grad_norm": 0.08525774627923965,
      "learning_rate": 0.00013805853000252585,
      "loss": 0.0084,
      "step": 210
    },
    {
      "epoch": 0.3964469378214119,
      "grad_norm": 0.0917392149567604,
      "learning_rate": 0.00013693624058133574,
      "loss": 0.0089,
      "step": 212
    },
    {
      "epoch": 0.4001870032725573,
      "grad_norm": 0.09064553678035736,
      "learning_rate": 0.0001358085377316211,
      "loss": 0.0086,
      "step": 214
    },
    {
      "epoch": 0.40392706872370265,
      "grad_norm": 0.08105634897947311,
      "learning_rate": 0.00013467558673113284,
      "loss": 0.0089,
      "step": 216
    },
    {
      "epoch": 0.40766713417484807,
      "grad_norm": 0.10329098254442215,
      "learning_rate": 0.00013353755362679857,
      "loss": 0.0085,
      "step": 218
    },
    {
      "epoch": 0.4114071996259935,
      "grad_norm": 0.0904826670885086,
      "learning_rate": 0.00013239460521038623,
      "loss": 0.0094,
      "step": 220
    },
    {
      "epoch": 0.41514726507713884,
      "grad_norm": 0.06706170737743378,
      "learning_rate": 0.00013124690899405902,
      "loss": 0.0083,
      "step": 222
    },
    {
      "epoch": 0.41888733052828425,
      "grad_norm": 0.11651502549648285,
      "learning_rate": 0.00013009463318582447,
      "loss": 0.0089,
      "step": 224
    },
    {
      "epoch": 0.42262739597942967,
      "grad_norm": 0.09769697487354279,
      "learning_rate": 0.00012893794666488174,
      "loss": 0.008,
      "step": 226
    },
    {
      "epoch": 0.426367461430575,
      "grad_norm": 0.06655571609735489,
      "learning_rate": 0.00012777701895687034,
      "loss": 0.008,
      "step": 228
    },
    {
      "epoch": 0.43010752688172044,
      "grad_norm": 0.08119421452283859,
      "learning_rate": 0.00012661202020902433,
      "loss": 0.0074,
      "step": 230
    },
    {
      "epoch": 0.43384759233286585,
      "grad_norm": 0.06770516186952591,
      "learning_rate": 0.00012544312116523506,
      "loss": 0.0078,
      "step": 232
    },
    {
      "epoch": 0.4375876577840112,
      "grad_norm": 0.07702741026878357,
      "learning_rate": 0.00012427049314102707,
      "loss": 0.0082,
      "step": 234
    },
    {
      "epoch": 0.4413277232351566,
      "grad_norm": 0.08555971086025238,
      "learning_rate": 0.0001230943079984495,
      "loss": 0.007,
      "step": 236
    },
    {
      "epoch": 0.44506778868630203,
      "grad_norm": 0.08072731643915176,
      "learning_rate": 0.0001219147381208879,
      "loss": 0.0071,
      "step": 238
    },
    {
      "epoch": 0.4488078541374474,
      "grad_norm": 0.05406467989087105,
      "learning_rate": 0.00012073195638779943,
      "loss": 0.0064,
      "step": 240
    },
    {
      "epoch": 0.4525479195885928,
      "grad_norm": 0.0724266842007637,
      "learning_rate": 0.00011954613614937549,
      "loss": 0.007,
      "step": 242
    },
    {
      "epoch": 0.4562879850397382,
      "grad_norm": 0.06334219872951508,
      "learning_rate": 0.00011835745120113508,
      "loss": 0.0069,
      "step": 244
    },
    {
      "epoch": 0.4600280504908836,
      "grad_norm": 0.06008293479681015,
      "learning_rate": 0.00011716607575845326,
      "loss": 0.0071,
      "step": 246
    },
    {
      "epoch": 0.463768115942029,
      "grad_norm": 0.06019603833556175,
      "learning_rate": 0.0001159721844310278,
      "loss": 0.0071,
      "step": 248
    },
    {
      "epoch": 0.4675081813931744,
      "grad_norm": 0.08160965889692307,
      "learning_rate": 0.00011477595219728817,
      "loss": 0.0062,
      "step": 250
    },
    {
      "epoch": 0.4675081813931744,
      "eval_loss": 0.20242996513843536,
      "eval_runtime": 176.8153,
      "eval_samples_per_second": 5.559,
      "eval_steps_per_second": 1.391,
      "step": 250
    },
    {
      "epoch": 0.47124824684431976,
      "grad_norm": 0.058129362761974335,
      "learning_rate": 0.0001135775543787504,
      "loss": 0.0063,
      "step": 252
    },
    {
      "epoch": 0.4749883122954652,
      "grad_norm": 0.06742126494646072,
      "learning_rate": 0.00011237716661432181,
      "loss": 0.0063,
      "step": 254
    },
    {
      "epoch": 0.4787283777466106,
      "grad_norm": 0.0679161548614502,
      "learning_rate": 0.00011117496483455898,
      "loss": 0.0075,
      "step": 256
    },
    {
      "epoch": 0.48246844319775595,
      "grad_norm": 0.058403611183166504,
      "learning_rate": 0.00010997112523588322,
      "loss": 0.0064,
      "step": 258
    },
    {
      "epoch": 0.48620850864890136,
      "grad_norm": 0.09371478855609894,
      "learning_rate": 0.00010876582425475694,
      "loss": 0.0059,
      "step": 260
    },
    {
      "epoch": 0.4899485741000468,
      "grad_norm": 0.06343289464712143,
      "learning_rate": 0.00010755923854182483,
      "loss": 0.0056,
      "step": 262
    },
    {
      "epoch": 0.49368863955119213,
      "grad_norm": 0.06332366168498993,
      "learning_rate": 0.0001063515449360238,
      "loss": 0.0062,
      "step": 264
    },
    {
      "epoch": 0.49742870500233755,
      "grad_norm": 0.056181102991104126,
      "learning_rate": 0.00010514292043866499,
      "loss": 0.006,
      "step": 266
    },
    {
      "epoch": 0.501168770453483,
      "grad_norm": 0.04976457729935646,
      "learning_rate": 0.00010393354218749248,
      "loss": 0.0058,
      "step": 268
    },
    {
      "epoch": 0.5049088359046283,
      "grad_norm": 0.05429702252149582,
      "learning_rate": 0.00010272358743072152,
      "loss": 0.0057,
      "step": 270
    },
    {
      "epoch": 0.5086489013557737,
      "grad_norm": 0.05502179637551308,
      "learning_rate": 0.00010151323350106088,
      "loss": 0.0051,
      "step": 272
    },
    {
      "epoch": 0.5123889668069191,
      "grad_norm": 0.04797250032424927,
      "learning_rate": 0.0001003026577897227,
      "loss": 0.0053,
      "step": 274
    },
    {
      "epoch": 0.5161290322580645,
      "grad_norm": 0.04314505308866501,
      "learning_rate": 9.909203772042369e-05,
      "loss": 0.0054,
      "step": 276
    },
    {
      "epoch": 0.5198690977092099,
      "grad_norm": 0.04811744764447212,
      "learning_rate": 9.788155072338185e-05,
      "loss": 0.0056,
      "step": 278
    },
    {
      "epoch": 0.5236091631603553,
      "grad_norm": 0.055308952927589417,
      "learning_rate": 9.667137420931173e-05,
      "loss": 0.005,
      "step": 280
    },
    {
      "epoch": 0.5273492286115007,
      "grad_norm": 0.052930235862731934,
      "learning_rate": 9.546168554342322e-05,
      "loss": 0.0049,
      "step": 282
    },
    {
      "epoch": 0.531089294062646,
      "grad_norm": 0.05528547614812851,
      "learning_rate": 9.425266201942645e-05,
      "loss": 0.0055,
      "step": 284
    },
    {
      "epoch": 0.5348293595137915,
      "grad_norm": 0.0374591089785099,
      "learning_rate": 9.30444808335473e-05,
      "loss": 0.0052,
      "step": 286
    },
    {
      "epoch": 0.5385694249649369,
      "grad_norm": 0.05291659012436867,
      "learning_rate": 9.183731905855746e-05,
      "loss": 0.0048,
      "step": 288
    },
    {
      "epoch": 0.5423094904160822,
      "grad_norm": 0.047730207443237305,
      "learning_rate": 9.063135361782227e-05,
      "loss": 0.0047,
      "step": 290
    },
    {
      "epoch": 0.5460495558672277,
      "grad_norm": 0.03460153564810753,
      "learning_rate": 8.942676125937061e-05,
      "loss": 0.0047,
      "step": 292
    },
    {
      "epoch": 0.5497896213183731,
      "grad_norm": 0.03771589323878288,
      "learning_rate": 8.82237185299904e-05,
      "loss": 0.0045,
      "step": 294
    },
    {
      "epoch": 0.5535296867695184,
      "grad_norm": 0.04910707473754883,
      "learning_rate": 8.702240174935376e-05,
      "loss": 0.0052,
      "step": 296
    },
    {
      "epoch": 0.5572697522206639,
      "grad_norm": 0.04379860684275627,
      "learning_rate": 8.582298698417528e-05,
      "loss": 0.005,
      "step": 298
    },
    {
      "epoch": 0.5610098176718092,
      "grad_norm": 0.030626565217971802,
      "learning_rate": 8.462565002240732e-05,
      "loss": 0.0045,
      "step": 300
    },
    {
      "epoch": 0.5610098176718092,
      "eval_loss": 0.20953653752803802,
      "eval_runtime": 176.6686,
      "eval_samples_per_second": 5.564,
      "eval_steps_per_second": 1.392,
      "step": 300
    },
    {
      "epoch": 0.5647498831229546,
      "grad_norm": 0.04281463101506233,
      "learning_rate": 8.34305663474765e-05,
      "loss": 0.0045,
      "step": 302
    },
    {
      "epoch": 0.5684899485741001,
      "grad_norm": 0.03920966759324074,
      "learning_rate": 8.223791111256447e-05,
      "loss": 0.0044,
      "step": 304
    },
    {
      "epoch": 0.5722300140252454,
      "grad_norm": 0.04591113328933716,
      "learning_rate": 8.104785911493719e-05,
      "loss": 0.0041,
      "step": 306
    },
    {
      "epoch": 0.5759700794763908,
      "grad_norm": 0.03658134862780571,
      "learning_rate": 7.986058477032637e-05,
      "loss": 0.0045,
      "step": 308
    },
    {
      "epoch": 0.5797101449275363,
      "grad_norm": 0.03977254405617714,
      "learning_rate": 7.867626208736703e-05,
      "loss": 0.0048,
      "step": 310
    },
    {
      "epoch": 0.5834502103786816,
      "grad_norm": 0.0406513437628746,
      "learning_rate": 7.749506464209428e-05,
      "loss": 0.0043,
      "step": 312
    },
    {
      "epoch": 0.587190275829827,
      "grad_norm": 0.04222336784005165,
      "learning_rate": 7.6317165552504e-05,
      "loss": 0.0045,
      "step": 314
    },
    {
      "epoch": 0.5909303412809724,
      "grad_norm": 0.05896558240056038,
      "learning_rate": 7.514273745318033e-05,
      "loss": 0.0055,
      "step": 316
    },
    {
      "epoch": 0.5946704067321178,
      "grad_norm": 0.033966921269893646,
      "learning_rate": 7.397195246999391e-05,
      "loss": 0.0048,
      "step": 318
    },
    {
      "epoch": 0.5984104721832632,
      "grad_norm": 0.033875733613967896,
      "learning_rate": 7.280498219487525e-05,
      "loss": 0.0046,
      "step": 320
    },
    {
      "epoch": 0.6021505376344086,
      "grad_norm": 0.037879783660173416,
      "learning_rate": 7.164199766066571e-05,
      "loss": 0.0044,
      "step": 322
    },
    {
      "epoch": 0.605890603085554,
      "grad_norm": 0.050043221563100815,
      "learning_rate": 7.048316931605062e-05,
      "loss": 0.0043,
      "step": 324
    },
    {
      "epoch": 0.6096306685366993,
      "grad_norm": 0.03391329571604729,
      "learning_rate": 6.932866700057832e-05,
      "loss": 0.0045,
      "step": 326
    },
    {
      "epoch": 0.6133707339878448,
      "grad_norm": 0.02567327953875065,
      "learning_rate": 6.817865991976805e-05,
      "loss": 0.0048,
      "step": 328
    },
    {
      "epoch": 0.6171107994389902,
      "grad_norm": 0.050672002136707306,
      "learning_rate": 6.703331662031098e-05,
      "loss": 0.0043,
      "step": 330
    },
    {
      "epoch": 0.6208508648901355,
      "grad_norm": 0.02962815947830677,
      "learning_rate": 6.589280496536778e-05,
      "loss": 0.0042,
      "step": 332
    },
    {
      "epoch": 0.624590930341281,
      "grad_norm": 0.04968748241662979,
      "learning_rate": 6.475729210996637e-05,
      "loss": 0.0041,
      "step": 334
    },
    {
      "epoch": 0.6283309957924264,
      "grad_norm": 0.02372485026717186,
      "learning_rate": 6.362694447650348e-05,
      "loss": 0.0042,
      "step": 336
    },
    {
      "epoch": 0.6320710612435717,
      "grad_norm": 0.03639618679881096,
      "learning_rate": 6.250192773035333e-05,
      "loss": 0.004,
      "step": 338
    },
    {
      "epoch": 0.6358111266947172,
      "grad_norm": 0.030868256464600563,
      "learning_rate": 6.138240675558778e-05,
      "loss": 0.004,
      "step": 340
    },
    {
      "epoch": 0.6395511921458625,
      "grad_norm": 0.03609761595726013,
      "learning_rate": 6.026854563081046e-05,
      "loss": 0.0038,
      "step": 342
    },
    {
      "epoch": 0.6432912575970079,
      "grad_norm": 0.08740479499101639,
      "learning_rate": 5.9160507605109275e-05,
      "loss": 0.0051,
      "step": 344
    },
    {
      "epoch": 0.6470313230481534,
      "grad_norm": 0.029689397662878036,
      "learning_rate": 5.805845507413032e-05,
      "loss": 0.0037,
      "step": 346
    },
    {
      "epoch": 0.6507713884992987,
      "grad_norm": 0.020643938332796097,
      "learning_rate": 5.6962549556277134e-05,
      "loss": 0.0038,
      "step": 348
    },
    {
      "epoch": 0.6545114539504441,
      "grad_norm": 0.0210892241448164,
      "learning_rate": 5.5872951669037855e-05,
      "loss": 0.0041,
      "step": 350
    },
    {
      "epoch": 0.6545114539504441,
      "eval_loss": 0.20504437386989594,
      "eval_runtime": 177.1812,
      "eval_samples_per_second": 5.548,
      "eval_steps_per_second": 1.388,
      "step": 350
    },
    {
      "epoch": 0.6582515194015895,
      "grad_norm": 0.039602722972631454,
      "learning_rate": 5.478982110544555e-05,
      "loss": 0.0042,
      "step": 352
    },
    {
      "epoch": 0.6619915848527349,
      "grad_norm": 0.036461617797613144,
      "learning_rate": 5.371331661067284e-05,
      "loss": 0.004,
      "step": 354
    },
    {
      "epoch": 0.6657316503038803,
      "grad_norm": 0.029972201213240623,
      "learning_rate": 5.264359595876618e-05,
      "loss": 0.0043,
      "step": 356
    },
    {
      "epoch": 0.6694717157550257,
      "grad_norm": 0.02496202476322651,
      "learning_rate": 5.158081592952236e-05,
      "loss": 0.0039,
      "step": 358
    },
    {
      "epoch": 0.6732117812061711,
      "grad_norm": 0.04726344347000122,
      "learning_rate": 5.052513228551048e-05,
      "loss": 0.0038,
      "step": 360
    },
    {
      "epoch": 0.6769518466573166,
      "grad_norm": 0.034191399812698364,
      "learning_rate": 4.9476699749243174e-05,
      "loss": 0.004,
      "step": 362
    },
    {
      "epoch": 0.6806919121084619,
      "grad_norm": 0.03911770135164261,
      "learning_rate": 4.843567198050031e-05,
      "loss": 0.004,
      "step": 364
    },
    {
      "epoch": 0.6844319775596073,
      "grad_norm": 0.027022402733564377,
      "learning_rate": 4.74022015538085e-05,
      "loss": 0.0036,
      "step": 366
    },
    {
      "epoch": 0.6881720430107527,
      "grad_norm": 0.016758639365434647,
      "learning_rate": 4.6376439936079284e-05,
      "loss": 0.0037,
      "step": 368
    },
    {
      "epoch": 0.6919121084618981,
      "grad_norm": 0.03225487843155861,
      "learning_rate": 4.535853746441018e-05,
      "loss": 0.0041,
      "step": 370
    },
    {
      "epoch": 0.6956521739130435,
      "grad_norm": 0.02280760556459427,
      "learning_rate": 4.4348643324050853e-05,
      "loss": 0.0037,
      "step": 372
    },
    {
      "epoch": 0.6993922393641889,
      "grad_norm": 0.024128630757331848,
      "learning_rate": 4.3346905526538574e-05,
      "loss": 0.0037,
      "step": 374
    },
    {
      "epoch": 0.7031323048153343,
      "grad_norm": 0.021470578387379646,
      "learning_rate": 4.2353470888005156e-05,
      "loss": 0.0037,
      "step": 376
    },
    {
      "epoch": 0.7068723702664796,
      "grad_norm": 0.0190958883613348,
      "learning_rate": 4.136848500765948e-05,
      "loss": 0.0035,
      "step": 378
    },
    {
      "epoch": 0.7106124357176251,
      "grad_norm": 0.020738812163472176,
      "learning_rate": 4.039209224644845e-05,
      "loss": 0.0037,
      "step": 380
    },
    {
      "epoch": 0.7143525011687705,
      "grad_norm": 0.07968837022781372,
      "learning_rate": 3.9424435705898824e-05,
      "loss": 0.0044,
      "step": 382
    },
    {
      "epoch": 0.7180925666199158,
      "grad_norm": 0.020891113206744194,
      "learning_rate": 3.846565720714451e-05,
      "loss": 0.0037,
      "step": 384
    },
    {
      "epoch": 0.7218326320710613,
      "grad_norm": 0.017857028171420097,
      "learning_rate": 3.751589727014075e-05,
      "loss": 0.0036,
      "step": 386
    },
    {
      "epoch": 0.7255726975222067,
      "grad_norm": 0.02193606272339821,
      "learning_rate": 3.657529509306939e-05,
      "loss": 0.0034,
      "step": 388
    },
    {
      "epoch": 0.729312762973352,
      "grad_norm": 0.020819617435336113,
      "learning_rate": 3.5643988531937924e-05,
      "loss": 0.0034,
      "step": 390
    },
    {
      "epoch": 0.7330528284244975,
      "grad_norm": 0.021173156797885895,
      "learning_rate": 3.472211408037488e-05,
      "loss": 0.0035,
      "step": 392
    },
    {
      "epoch": 0.7367928938756428,
      "grad_norm": 0.020582422614097595,
      "learning_rate": 3.3809806849625314e-05,
      "loss": 0.0039,
      "step": 394
    },
    {
      "epoch": 0.7405329593267882,
      "grad_norm": 0.049018893390893936,
      "learning_rate": 3.2907200548748596e-05,
      "loss": 0.0038,
      "step": 396
    },
    {
      "epoch": 0.7442730247779337,
      "grad_norm": 0.037336234003305435,
      "learning_rate": 3.201442746502201e-05,
      "loss": 0.0039,
      "step": 398
    },
    {
      "epoch": 0.748013090229079,
      "grad_norm": 0.03417922183871269,
      "learning_rate": 3.1131618444552145e-05,
      "loss": 0.0037,
      "step": 400
    },
    {
      "epoch": 0.748013090229079,
      "eval_loss": 0.20334826409816742,
      "eval_runtime": 176.7772,
      "eval_samples_per_second": 5.561,
      "eval_steps_per_second": 1.392,
      "step": 400
    }
  ],
  "logging_steps": 2,
  "max_steps": 534,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 50,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 3
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.2632085353136128e+18,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
